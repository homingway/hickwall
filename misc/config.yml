#TODO: config hostname
# customize hostname, if omit this option, the client will use $(hostname) automatically
# hostname: "test_server1"

#TODO: split config into configuration folder
#2015Mar04 DONE TODO: normalize metric, only `a-z._` allowed in metric
#2015Mar04 DONE TODO: normalize tags

# these tags will be appended into metrics' tags field. 
tags: {
    "bu": "hotel",
    "global": "tag",
}

#TODO: enable_metadata
# only opentsdb support metadata
enable_metadata: false

#TODO: merge_metadata_to_tags
# If enable metadata, but backend don't support metadata. this option will merge all metadata
# into tags
merge_metadata_to_tags: false

#TODO: debug flag
debug: false

#TODO: memory_limit_in_mb
# when use 'memory' transport cache backend, we have to set a hard limit to prevent memory leak
# once this limit reached, the client will restart automatically
memory_limit_in_mb: 500

# ---------- log configurations -------------------------------------------
# only works in *nix like system
log_colored_console: true

# Levels: trace, debug, info, warn, error, critical
log_console_level: "info"

#TODO: log format instruction
# Format :
log_console_format: "%Time [%LEV] %Msg%n"

#TODO: different log path on different OS
log_file_filepath: "/var/log/hickwall/hickwall.log"
#log_file_filepath: "c:\\hickwall\\hickwall.log"

log_file_level: "debug"
log_file_format: "%Date %Time [%Level] %RelFile %Msg%n"
#log_file_format: "%Date(2006 Jan 02/3:04:05.000000000 PM MST) [%Level] %RelFile %Msg%n"

# calculated in Mb
log_file_maxsize: 100

#
log_file_maxrolls: 5

# ---------- transport configurations -------------------------------------------

#TODO: transport_flat_metric_key_format
# graphtie and influxdb version below 0.9 don't support tags.  So we need to flatten the metric key with tags
# transport flat metric key format instruction:
#  
#  {key}        is the original metric key predefiend when the collector was created, which is a string. 
#               you can only move its position back and forth. 
#  {hostname}   hostname
#  {tags}       is the tags field of the original metric object. which is like a dict in python with key-value pairs.
#               if a metric point have a tags lets say: { host: "dev1", bu: "hotel" }, and you place `{tags}` in
#               the option, the client will sort tags by key and join all value with "_", which with the previous
#               example data, this string will be generated: "hotel_dev1"
#  {tags.xxx}   you can also reference field of tags directly. once a field is referenced, it will be poped out, so
#               all fields in {tags} will only appear once in generated flat metric key.  so if you have `{tgas.xxx}` 
#               and `{tags}` in the option at the same time, then `{tags}` will only applys to the remaining tags 
transport_flat_metric_key_format: "hotel.{tags.bu}.{hostname}.{key}.{tags}"

#TODO: config transport_backfill_enabled
# when transport target host failed, the client will try to cache up requests into a file queue. once the target host
# back online again, the client will try to send cached requests back into target host. 
# this option can turn it on/off.  if this option is off, no reqeust will be cached.
transport_backfill_enabled: false

# Try the best to report latest data to upstream is the core concept of the collector daemon. and then try to evenly
# distribute backfill workloads to prevent surge of pressure in upstream server. So two threads work seperately. 
# the first one report latest data with fixed interval, cache request if failed. 
# the second thread try to backfill data in cache with all following tweaks.

#TODO: config transport_queue_full_method
# can be 'drop' or 'trim'.  `drop` means all incoming new request will be dropped. `trim` means to push incoming request
# into queue and trim queue size to max_queue_size(oldest request will be dropped.)
transport_queue_full_method: "trim"

# can be 'memory' or 'boltq'. `boltq` is a boltdb based simple file queue, which is not optmized for performance.  
transport_queue_backend: "memory"

#TODO: config transport_queue_max_size
# max cached reqeusts count
transport_queue_max_size: 10000000

# each backfill request will delay in seconds
transport_backfill_delay: 10

# each cached request will contain multiple data points. the client will try to merge several cached requests into one
# backfill request whlie backfilling. this option decide how many of cached reqeusts can be merged into one.
transport_backfill_batch: 2

# Whether the client will try to cool down a little while if a response latency threshold reached while backfilling.
transport_backfill_handsoff: false

# latency threshold in ms
transport_backfill_latency_threshold_ms: 500

# cool down period in seconds
transport_backfill_cool_down_sec: 120


# graphtie transport only support plain text protocol, and will automatically flatten metric key
transport_graphite_enabled: true
# send data to graphtie with this interval in seconds
transport_graphite_interval: 60
# transport_graphite_hosts: ["127.0.0.1:2003", "127.0.0.1:2004"]
transport_graphite_hosts: ["127.0.0.1:2003", "127.0.0.1:2004"]

# if influxdb version smaller than `0.9`, the client will automatically flatten metric key.
transport_influxdb_enabled: true
# send data to influxdb with this interval in seconds
transport_influxdb_interval: 10
transport_influxdb_version: "0.8.8"
# transport_influxdb_hosts: ["127.0.0.1:8086", "127.0.0.1:8087"]
transport_influxdb_database: "metrics"
transport_influxdb_username: "root"
transport_influxdb_password: "root"

# transport_backends:
#     - graphtie:
#         enabled: true
#         interval: 60
#         hosts: ["127.0.0.1:2003", "127.0.0.1:2004"]
#     - influxdb:
#         enabled: true
#         version: "0.8.8"
#         database: "metrics"
#         username: "root"
#         password: "root"


# TODO: support amqp transport
# transport_amqp_enabled: false
# transport_amqp_hosts: ["127.0.0.1:5672", "127.0.0.1:5672"]
# transport_amqp_vhost: "/"
# transport_amqp_username: "guest"
# transport_amqp_password: "guest"
# transport_amqp_exchange: "amq.fanout"
# transport_amqp_exchange_type: "fanout"
# transport_amqp_routing_key: "hickwall"
# transport_amqp_persistent: false
# transport_amqp_queue: "queuename"


# transport_kafka_enabled: true
# transport_kafka_hosts: ["127.0.0.1:2003", "127.0.0.1:2004"]

# ---------- relay configurations -------------------------------------------
# TODO: do we need to implement a rule based replay server ? or we just need a simplified relay server to go across 
# network segmentations ??

#TODO: config transport_relay_hosts
# send reqeust to relay hosts
# transport_relay_hosts: ["127.0.0.1:2345"]

# for performance sake, relay will only work in memory mode. 

# transport_relay_server: false
# transport_relay_server_upstream: ["127.0.0.1:2003", "127.0.0.1:2004"]
# transport_relay_server_rule: ""

# ---------- collector configurations -------------------------------------------

# interval in seconds
collector_default_interval: 1

# builtin collectors will always working without configurations

#TODO: metric key, tags configuration in collectors ?

#TODO: different collector type: gauge, counter 
#2015MAR03 DELETE TODO: [don't need]collectored value can be transformed into different units: bytes, mb, gb, ...

collector_win_pdh:
    - 
        interval: 2
        tags: {
            "bu": "train"
        }
        queries:
            -
                query: "\\System\\Processes"
                metric: "win.pdh.process_cnt"
                # metric: "win.processes.count"     duplicated metric key: win.processes.count
            - 
                query: "\\Memory\\Available Bytes"
                metric: "win.pdh.memory.available_bytes"

    - 
        interval: 2
        tags: {
            "bu": "train"
        }
        queries: 
            -
                query: "\\System\\Processes"
                metric: "win.pdh.process_cnt_1"
                tags: {
                    "mount": "C",
                    "prodution": "中文",
                }
                #TODO: support meta
                # meta: {
                #     "unit": "bytes"
                # }
            - 
                query: "\\Memory\\Available Bytes"
                metric: "win.pdh.memory.available_bytes_1"
                tags: {
                    "mount": "C"
                }


# This collector is supplement for win_pdh. and is not performace optimized. so should be used with 
# limitations. Internally, all queries with in this collector will be executed sequencially.
collector_win_wmi:
    - 
        interval: 2
        tags: {
            "bu": "train",
            "prodution": "中文"
        }

        queries: 
            # simplest query form. for single instance return query
            - 
                query: "wmic cpu get Name,NumberOfCores"
                metrics:
                    # character cases matters here!!  
                    -
                        value_from: "Name"
                        metric: "win.wmi.cpu.name"
                    -
                        value_from: "NumberOfCores"
                        metric: "win.wmi.cpu.numberofcores"

            # query with metric templating, tags for multiple instance return query
            - 
                # query: "wmic logicaldisk get Name, FileSystem, FreeSpace"
                query: "wmic logicaldisk where 'mediatype=11 or mediatype=12' get Name, FileSystem, FreeSpace, Size"

                #  map[FreeSpace: Name:A: FileSystem:]
                #  map[Name:C: FileSystem:NTFS FreeSpace:57517752320]
                #  map[FileSystem:CDFS FreeSpace:0 Name:D:]

                tags: {
                    "tag_level": "query_tag"
                }
                # metric string is a template. {Name} means use the value of `Name` Field of collected record. 
                metrics:
                    # character cases matters here!!  
                    -
                        value_from: "Size"
                        metric: "win.wmi.fs.{{.Name}}.{{.FileSystem}}.size.bytes"
                        tags: {
                            "mount": "{{.Name}}",
                            "fs_type": "{{.FileSystem}}",
                        }
                    -
                        value_from: "FreeSpace"
                        metric: "win.wmi.fs.{{.Name}}.{{.FileSystem}}.freespace.bytes"
                        tags: {
                            "mount": "{{.Name}}",
                            "fs_type": "{{.FileSystem}}",
                        }
                        #TODO: support meta
                        # meta: {
                        #     "unit": "bytes"
                        # }
                    - 
                        value_from: "FileSystem"
                        metric: "win.wmi.fs.{{.Name}}.filesystem"

# TODO: collector_mysql_query
# collector_mysql_query:
#     - 
#         tags: [
#             [ "bu", "test" ],
#         ]
#         host     : "127.0.0.1"
#         port     : 3306
#         username : "root"
#         password : "root"

#         queries  :
#             -
#                 metric_key: "mysql_query.xxxxx"
#                 # tags: [
#                 #     [ "some", "test2"]
#                 # ]

#                 database: "db1"
#                 desc: "one line query"
#                 query: "SELECT count(*) as cnt, sum(*) as total FROM sometable where column=123"
#                 values_from: "cnt"

#             # metrics:
#             #   mysql_query.xxxx  {"bu":"test", "some", "test2"}      123

#             -
#                 database: "db1"
#                 desc: "multiple line query"
#                 # multiple line is tricky. indent is very important
#                 #
#                 #  xxxx: >
#                 #      a          =>  "a b\n"
#                 #      b
#                 #  xxxx: >
#                 #      a          =>  "a\n b\n"
#                 #       b
#                 query: >
#                     SELECT count(*) as cnt, sum(*) as
#                     total FROM sometable where column=123

#                 metric_key: "mysql_query.xxxxx"

#                 # multiple values from also ok
#                 values_from: "cnt, total"

#             # metrics:
#             #   mysql_query.xxxx.cnt    {"bu": "test"}  123
#             #   mysql_query.xxxx.total  {"bu": "test"}  432

# TODO: collector_ping
# collector_ping:
#     -
#         # in seconds
#         interval: 10
#         metric_key: "ping"
#         tags: [
#             [ "some", "test2"]
#         ]
#         hosts:
#             - "www.baidu.com"
#             - "www.12306.com"
#         timeout_ms: 1000ms
#         packets: 5
#         collect:
#             - "time_min"
#             - "time_avg"
#             - "time_max"
#             - "time_mdev"
#             - "lost_pct"

#         # metrics:
#         #   ping.time_min    {"some": "test2", "host": "www.baidu.com"}  28.307
#         #   ping.time_avg    {"some": "test2", "host": "www.baidu.com"}  30.372
#         #   ping.time_max    {"some": "test2", "host": "www.baidu.com"}  34.360
#         #   ping.time_mdev   {"some": "test2", "host": "www.baidu.com"}  2.192
#         #   ping.lost_pct    {"some": "test2", "host": "www.baidu.com"}  0.0

#         #   ping.time_min    {"some": "test2", "host": "www.12306.com"}  28.307
#         #   ping.time_avg    {"some": "test2", "host": "www.12306.com"}  30.372
#         #   ping.time_max    {"some": "test2", "host": "www.12306.com"}  34.360
#         #   ping.time_mdev   {"some": "test2", "host": "www.12306.com"}  2.192
#         #   ping.lost_pct    {"some": "test2", "host": "www.12306.com"}  0.0


# collecotr_linux:
# collector_darwin:

# plugin_cmd:
#     - 
#         alias: "cmd1"
#         cmd: "/bin/echo"
#         regex: "/"

# plugin_cmd:
#     -
#         alias: "python"
#         cmd: "/bin/python /path/to/py/script.py"
#         regex: "\d+"







