# port: ":9977"

#TODO: config hostname
# customize hostname, if omit this option, the client will use $(hostname) automatically
# hostname: "test_server1"

#TODO: config tags
# these tags will be appended into metrics' tags field.   ['key', 'value']
# tags: [
#     ['bu', 'hotel'], 
#     ['group', 'test']
# ]

#TODO: memory_limit_in_mb
# when use 'memory' transport cache backend, we have to set a hard limit to prevent memory leak
# once this limit reached, the client will restart automatically
memory_limit_in_mb: 500

# ---------- log configurations -------------------------------------------
# only works in *nix like system
log_colored_console: true

# Levels: trace, debug, info, warn, error, critical
log_console_level: "info"

#TODO: log format instruction
# Format :
log_console_format: "%Time [%LEV] %Msg%n"

#TODO: different log path on different OS
log_file_filepath: "/var/log/hickwall/hickwall.log"
#log_file_filepath: "c:\\hickwall\\hickwall.log"

log_file_level: "debug"
log_file_format: "%Date %Time [%Level] %RelFile %Msg%n"
#log_file_format: "%Date(2006 Jan 02/3:04:05.000000000 PM MST) [%Level] %RelFile %Msg%n"

# calculated in Mb
log_file_maxsize: 100

#
log_file_maxrolls: 5

# ---------- transport configurations -------------------------------------------

#TODO: transport_flat_metric_key_format
# graphtie and influxdb version below 0.9 don't support tags.  So we need to flatten the metric key with tags
# transport flat metric key format instruction:
#  
#  {key}        is the original metric key predefiend when the collector was created, which is a string. 
#               you can only move its position back and forth. 
#  {hostname}   hostname
#  {tags}       is the tags field of the original metric object. which is like a dict in python with key-value pairs.
#               if a metric point have a tags lets say: { host: "dev1", bu: "hotel" }, and you place `{tags}` in
#               the option, the client will sort tags by key and join all value with "_", which with the previous
#               example data, this string will be generated: "hotel_dev1"
#  {tags.xxx}   you can also reference field of tags directly. once a field is referenced, it will be poped out, so
#               all fields in {tags} will only appear once in generated flat metric key.  so if you have `{tgas.xxx}` 
#               and `{tags}` in the option at the same time, then `{tags}` will only applys to the remaining tags 
transport_flat_metric_key_format: "hotel.{tags.bu}.{hostname}.{key}.{tags}"

#TODO: config transport_backfill_enabled
# when transport target host failed, the client will try to cache up requests into a file queue. once the target host
# back online again, the client will try to send cached requests back into target host. 
# this option can turn it on/off.  if this option is off, no reqeust will be cached.
transport_backfill_enabled: false

# Try the best to report latest data to upstream is the core concept of the collector daemon. and then try to evenly
# distribute backfill workloads to prevent surge of pressure in upstream server. So two threads work seperately. 
# the first one report latest data with fixed interval, cache request if failed. 
# the second thread try to backfill data in cache with all following tweaks.

#TODO: config transport_queue_full_method
# can be 'drop' or 'trim'.  `drop` means all incoming new request will be dropped. `trim` means to push incoming request
# into queue and trim queue size to max_queue_size(oldest request will be dropped.)
transport_queue_full_method: "trim"

# can be 'memory' or 'boltq'. `boltq` is a boltdb based simple file queue, which is not optmized for performance.  
transport_queue_backend: "memory"

#TODO: config transport_queue_max_size
# max cached reqeusts count
transport_queue_max_size: 10000000

# each backfill request will delay in seconds
transport_backfill_delay: 10

# each cached request will contain multiple data points. the client will try to merge several cached requests into one
# backfill request whlie backfilling. this option decide how many of cached reqeusts can be merged into one.
transport_backfill_batch: 2

# Whether the client will try to cool down a little while if a response latency threshold reached while backfilling.
transport_backfill_handsoff: false

# latency threshold in ms
transport_backfill_latency_threshold_ms: 500

# cool down period in seconds
transport_backfill_cool_down_sec: 120


# graphtie transport only support plain text protocol, and will automatically flatten metric key
transport_graphite_enabled: true
# send data to graphtie with this interval in seconds
transport_graphite_interval: 60
# transport_graphite_hosts: ["127.0.0.1:2003", "127.0.0.1:2004"]
transport_graphite_hosts: ["127.0.0.1:2003", "127.0.0.1:2004"]

# if influxdb version smaller than `0.9`, the client will automatically flatten metric key.
transport_influxdb_enabled: true
# send data to influxdb with this interval in seconds
transport_influxdb_interval: 10
transport_influxdb_version: "0.8.8"
# transport_influxdb_hosts: ["127.0.0.1:8086", "127.0.0.1:8087"]
transport_influxdb_database: "metrics"
transport_influxdb_username: "root"
transport_influxdb_password: "root"

# transport_backends:
#     - graphtie:
#         enabled: true
#         interval: 60
#         hosts: ["127.0.0.1:2003", "127.0.0.1:2004"]
#     - influxdb:
#         enabled: true
#         version: "0.8.8"
#         database: "metrics"
#         username: "root"
#         password: "root"


# TODO: support amqp transport
# transport_amqp_enabled: false
# transport_amqp_hosts: ["127.0.0.1:5672", "127.0.0.1:5672"]
# transport_amqp_vhost: "/"
# transport_amqp_username: "guest"
# transport_amqp_password: "guest"
# transport_amqp_exchange: "amq.fanout"
# transport_amqp_exchange_type: "fanout"
# transport_amqp_routing_key: "hickwall"
# transport_amqp_persistent: false
# transport_amqp_queue: "queuename"


# transport_kafka_enabled: true
# transport_kafka_hosts: ["127.0.0.1:2003", "127.0.0.1:2004"]

# ---------- relay configurations -------------------------------------------
# TODO: do we need to implement a rule based replay server ? or we just need a simplified relay server to go across 
# network segmentations ??

#TODO: config transport_relay_hosts
# send reqeust to relay hosts
# transport_relay_hosts: ["127.0.0.1:2345"]

# for performance sake, relay will only work in memory mode. 

# transport_relay_server: false
# transport_relay_server_upstream: ["127.0.0.1:2003", "127.0.0.1:2004"]
# transport_relay_server_rule: ""

# ---------- collector configurations -------------------------------------------

# interval in seconds
collector_default_interval: 1

# builtin collectors will always working without configurations

#TODO: metric key, tags configuration in collectors ?

# metric_key will be concatenated with "." from top to bottom. and generated metric_key cannot be duplicated.
# tags will also be merged from top to bottom, but if the same key exists in lower level structure, then 
#  the tags in lower level structure will override the finial result.  don't forget about global tags config

#TODO: collector_win_pdh
collector_win_pdh:
    - 
        interval: 2
        tags: [
            ["bu", "hotel"],
        ]

        # query: metric_key
        queries: {
            "\\System\\Processes": "win.pdh.process_cnt",
            "\\Memory\\Available Bytes": "win.pdh.memory.available_bytes",
        }

    - 
        interval: 2
        queries: {
            "\\System\\Processes": "win.pdh.process_cnt",
            "\\Memory\\Available Bytes": "win.pdh.memory.available_bytes",
        }

# TODO: collector_mysql_query
collector_mysql_query:
    - 
        tags: [
            [ "bu", "test" ],
        ]
        host     : "127.0.0.1"
        port     : 3306
        username : "root"
        password : "root"

        queries  :
            -
                metric_key: "mysql_query.xxxxx"
                # tags: [
                #     [ "some", "test2"]
                # ]

                database: "db1"
                desc: "one line query"
                query: "SELECT count(*) as cnt, sum(*) as total FROM sometable where column=123"
                values_from: "cnt"

            # metrics:
            #   mysql_query.xxxx  {"bu":"test", "some", "test2"}      123

            -
                database: "db1"
                desc: "multiple line query"
                # multiple line is tricky. indent is very important
                #
                #  xxxx: >
                #      a          =>  "a b\n"
                #      b
                #  xxxx: >
                #      a          =>  "a\n b\n"
                #       b
                query: >
                    SELECT count(*) as cnt, sum(*) as
                    total FROM sometable where column=123

                metric_key: "mysql_query.xxxxx"

                # multiple values from also ok
                values_from: "cnt, total"

            # metrics:
            #   mysql_query.xxxx.cnt    {"bu": "test"}  123
            #   mysql_query.xxxx.total  {"bu": "test"}  432

# TODO: collector_ping
collector_ping:
    -
        # in seconds
        interval: 10
        metric_key: "ping"
        tags: [
            [ "some", "test2"]
        ]
        hosts:
            - "www.baidu.com"
            - "www.12306.com"
        timeout_ms: 1000ms
        packets: 5
        collect:
            - "time_min"
            - "time_avg"
            - "time_max"
            - "time_mdev"
            - "lost_pct"

        # metrics:
        #   ping.time_min    {"some": "test2", "host": "www.baidu.com"}  28.307
        #   ping.time_avg    {"some": "test2", "host": "www.baidu.com"}  30.372
        #   ping.time_max    {"some": "test2", "host": "www.baidu.com"}  34.360
        #   ping.time_mdev   {"some": "test2", "host": "www.baidu.com"}  2.192
        #   ping.lost_pct    {"some": "test2", "host": "www.baidu.com"}  0.0

        #   ping.time_min    {"some": "test2", "host": "www.12306.com"}  28.307
        #   ping.time_avg    {"some": "test2", "host": "www.12306.com"}  30.372
        #   ping.time_max    {"some": "test2", "host": "www.12306.com"}  34.360
        #   ping.time_mdev   {"some": "test2", "host": "www.12306.com"}  2.192
        #   ping.lost_pct    {"some": "test2", "host": "www.12306.com"}  0.0


# collecotr_linux:
# collector_darwin:

# plugin_cmd:
#     - 
#         alias: "cmd1"
#         cmd: "/bin/echo"
#         regex: "/"

# plugin_cmd:
#     -
#         alias: "python"
#         cmd: "/bin/python /path/to/py/script.py"
#         regex: "\d+"







